{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5X6oORSzxjU3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/repos/Epilepsy_Microglia\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAYlADIBtNYY"
   },
   "outputs": [],
   "source": [
    "# Single Cell Libraries\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "# Data Processing and Plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# File grab\n",
    "import os\n",
    "import tempfile\n",
    "import pooch\n",
    "import shutil, subprocess, glob\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code-server\n",
      "/home/neuro_demo_research/data_from_drive/Epilepsy_Microglia\n"
     ]
    }
   ],
   "source": [
    "# project name\n",
    "project = \"Epilepsy_Microglia\"\n",
    "dataset = \"thrupp\"\n",
    "gse_accession = \"GSE153807\"\n",
    "link = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE201048&format=file\"\n",
    "\n",
    "# environment setting\n",
    "from env_utils import detect_env, get_paths\n",
    "env = detect_env()\n",
    "paths = get_paths(project)\n",
    "print(env)\n",
    "print(paths[\"base\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(env == \"colab\"):\n",
    "    download_dir = Path(f\"/content/downloads/{dataset}\")\n",
    "elif(env == \"code-server\"):\n",
    "    download_dir = Path(f\"/home/neuro_demo_research/downloads/{dataset}\")\n",
    "else:\n",
    "    download_dir = Path(f\"~/neuro_demo_research/downloads/{dataset}\").expanduser()\n",
    "\n",
    "raw_dir = paths[\"raw\"] / dataset\n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(raw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goGqpAg4t2zo"
   },
   "outputs": [],
   "source": [
    "# A. downloading mtx type data\n",
    "\n",
    "LINK = DATA_INFO[\"LINK\"]\n",
    "FNAME = DATA_INFO[\"FNAME\"]\n",
    "RAW_DIR = DATA_INFO[\"RAW_DIR\"]\n",
    "OUT_DIR = DATA_INFO[\"OUT_DIR\"]\n",
    "LABEL = DATA_INFO[\"LABEL\"]\n",
    "\n",
    "# download + unpack\n",
    "subprocess.run([\"curl\", \"-L\", LINK, \"-o\", f\"{FNAME}.tar\"], check=True)\n",
    "subprocess.run([\"tar\", \"-xf\", f\"{FNAME}.tar\", \"-C\", RAW_DIR], check=True)\n",
    "os.remove(f\"{FNAME}.tar\")\n",
    "# normalize + regroup\n",
    "files = glob.glob(os.path.join(RAW_DIR, \"*\"))\n",
    "groups = {}\n",
    "for f in files:\n",
    "    fname_only = os.path.basename(f)\n",
    "    prefix = fname_only.split(\"_\")[0]\n",
    "    groups.setdefault(prefix, []).append(f)\n",
    "for prefix, flist in groups.items():\n",
    "    sample_dir = os.path.join(OUT_DIR, prefix)\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    for f in flist:\n",
    "        fname_only = os.path.basename(f)\n",
    "        if \"matrix.mtx\" in fname_only:\n",
    "            # check gunzip file\n",
    "            if fname_only.endswith(\".gz\"):\n",
    "                dest = os.path.join(sample_dir, \"matrix.mtx.gz\")\n",
    "            else:\n",
    "                dest = os.path.join(sample_dir, \"matrix.mtx\")\n",
    "        elif \"barcodes.tsv\" in fname_only:\n",
    "            if fname_only.endswith(\".gz\"):\n",
    "                dest = os.path.join(sample_dir, \"barcodes.tsv.gz\")\n",
    "            else:\n",
    "                dest = os.path.join(sample_dir, \"barcodes.tsv\")\n",
    "        elif \"genes.tsv\" in fname_only or \"features.tsv\" in fname_only:\n",
    "            if fname_only.endswith(\".gz\"):\n",
    "                dest = os.path.join(sample_dir, \"features.tsv.gz\")\n",
    "            else:\n",
    "                dest = os.path.join(sample_dir, \"features.tsv\")\n",
    "        else:\n",
    "            dest = os.path.join(sample_dir, fname_only)\n",
    "        shutil.move(f, dest)\n",
    "\n",
    "# build AnnData per sample and save separately\n",
    "for folder in sorted(glob.glob(os.path.join(OUT_DIR, \"*\"))):\n",
    "    if os.path.isdir(folder):\n",
    "        sample_id = os.path.basename(folder)\n",
    "        print(f\"Reading {folder}\")\n",
    "        ad = sc.read_10x_mtx(folder, var_names=\"gene_symbols\", make_unique=True)\n",
    "        if sample_id in sample_meta:\n",
    "          for key, value in sample_meta[sample_id].items():\n",
    "            ad.obs[key] = value\n",
    "        else:\n",
    "          print(f\"Warning: No metadata found for sample {sample_id}\")\n",
    "\n",
    "        # save\n",
    "        out_file = os.path.join(OUT_DIR, f\"{LABEL}_{sample_id}.h5ad\")\n",
    "        ad.write(out_file)\n",
    "        print(f\"Saved {out_file}\")\n",
    "        shutil.rmtree(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gb-J1fyNus0K"
   },
   "outputs": [],
   "source": [
    "# B-1. downloading csv/tsv type data\n",
    "\n",
    "LINK = DATA_INFO[\"LINK\"]\n",
    "FNAME = DATA_INFO[\"FNAME\"]\n",
    "RAW_DIR = DATA_INFO[\"RAW_DIR\"]\n",
    "OUT_DIR = DATA_INFO[\"OUT_DIR\"]\n",
    "LABEL = DATA_INFO[\"LABEL\"]\n",
    "\n",
    "subprocess.run([\"curl\", \"-L\", LINK, \"-o\", f\"{FNAME}.tar\"], check=True)\n",
    "subprocess.run([\"tar\", \"-xf\", f\"{FNAME}.tar\", \"-C\", RAW_DIR], check=True)\n",
    "os.remove(f\"{FNAME}.tar\")\n",
    "\n",
    "for f in glob.glob(os.path.join(RAW_DIR, \"*.gz\")):\n",
    "    fname_only = os.path.basename(f)\n",
    "    outpath = os.path.join(RAW_DIR, fname_only[:-3])  # remove \".gz\"\n",
    "    with gzip.open(f, 'rb') as f_in, open(outpath, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jPaBqi8u9YZ"
   },
   "outputs": [],
   "source": [
    "# B-2. transforming tsv to csv\n",
    "\n",
    "for tsvpath in glob.glob(os.path.join(RAW_DIR, \"*.tsv\")):\n",
    "    fname_only = os.path.splitext(os.path.basename(tsvpath))[0]\n",
    "    csvpath = os.path.join(OUT_DIR, f\"{fname_only}.csv\")\n",
    "    try:\n",
    "        df = pd.read_csv(tsvpath, sep=\"\\t\")\n",
    "        df.to_csv(csvpath, index=False)\n",
    "        os.remove(tsvpath)  # delete original.tsv\n",
    "        print(f\"Converted {tsvpath} -> {csvpath} (and deleted original)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {tsvpath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWYJW2VSvEbR"
   },
   "outputs": [],
   "source": [
    "# B-3. Transforming csv into h5ad\n",
    "\n",
    "# Check cell-gene orientation\n",
    "def check_csv_orientation(path, n_check=5):\n",
    "    df = pd.read_csv(path, index_col=0, nrows=n_check)\n",
    "    n_rows, n_cols = df.shape\n",
    "\n",
    "    row_idx = df.index[0]\n",
    "    col_idx = df.columns[0]\n",
    "\n",
    "    if row_idx.startswith(\"ENSG\") or row_idx.isalpha():\n",
    "        orientation = \"genes_as_rows\"\n",
    "    elif col_idx.startswith(\"ENSG\") or col_idx.isalpha():\n",
    "        orientation = \"genes_as_columns\"\n",
    "    else:\n",
    "        orientation = \"unknown\"\n",
    "\n",
    "    print(f\"{path}: {orientation} ({n_rows}X{n_cols})\")\n",
    "    return orientation\n",
    "\n",
    "intermediate_files = []\n",
    "\n",
    "# Read .csv into .h5ad\n",
    "for f in glob.glob(os.path.join(RAW_DIR, \"*.csv\")):\n",
    "  fname_only = os.path.splitext(os.path.basename(f))[0]\n",
    "\n",
    "  ori = check_csv_orientation(f)\n",
    "\n",
    "  if ori == \"genes_as_rows\":\n",
    "    adata = sc.read_csv(f, first_column_names=True)\n",
    "    adata = adata.T\n",
    "  elif ori == \"genes_as_columns\":\n",
    "    adata = sc.read_csv(f, first_column_names=True)\n",
    "  else:\n",
    "    raise ValueError(f\"Unknown orientation for {f}\")\n",
    "\n",
    "  adata.obs[\"sample\"] = fname_only\n",
    "  tmp_path = os.path.join(OUT_DIR, f\"{fname_only}.h5ad\")\n",
    "  adata.write(tmp_path)\n",
    "  intermediate_files.append(tmp_path)\n",
    "\n",
    "  print(f\"Converted {f} -> {tmp_path}\")\n",
    "  del adata\n",
    "  os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDRHzy_pvKTF"
   },
   "outputs": [],
   "source": [
    "# B-4. Merge adatas\n",
    "\n",
    "adatas = [sc.read_h5ad(f) for f in intermediate_files]\n",
    "\n",
    "adata_merged = sc.concat(adatas, join=\"outer\", label=\"sample\", keys=[os.path.basename(f).replace(\".h5ad\",\"\") for f in intermediate_files])\n",
    "\n",
    "merged_path = os.path.join(OUT_DIR, f\"{LABEL}_{FNAME}_merged.h5ad\")\n",
    "adata_merged.write(merged_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (scenv)",
   "language": "python",
   "name": "scenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
